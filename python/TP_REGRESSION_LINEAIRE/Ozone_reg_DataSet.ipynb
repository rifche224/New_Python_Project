{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2eeed49",
   "metadata": {},
   "source": [
    "# TP DE REGRESSION LINEAIRE\n",
    "\n",
    "**Crédits.** Ce TP est largement inspiré du scénario disponible sur Wikistat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173527c",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217433c",
   "metadata": {},
   "source": [
    "### Objectif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a455b1",
   "metadata": {},
   "source": [
    "L'objectif de cette est d'améliorer la prévision déterministe (MOCAGE), calculée par les services de Météo France, de la concentration d'ozone dans certaines stations de prélèvement. Il s'agit d'un problème dit d'adaptation statistique ou post-traitement d'une prévision locale de modèles à trop grande échelle en s'aidant d'autre variables également gérées par MétéoFrance, mais à plus petite échelle (température, force du vent, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19f337",
   "metadata": {},
   "source": [
    "### Description des données "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119d2e5",
   "metadata": {},
   "source": [
    "Les données ont été extraites et mises en forme par le service concerné de Météo France. Elles sont décrites par les variables suivantes:\n",
    "- JOUR : Type de jour (férié (1) ou pas (0) ;\n",
    "- O3obs : Concentration d'ozone effectivement observée le lendemain à 17h locales correspondant souvent au maximum de pollution observée ;\n",
    "- MOCAGE : Prévision de cette pollution obtenue par un modèle déterministe de mécanique des fluides (équation de Navier et Stockes);\n",
    "- TEMPE : Température prévue par MétéoFrance pour le lendemain 17h ;\n",
    "- RMH2O : Rapport d'humidité ;\n",
    "- NO2 : Concentration en dioxyde d'azote ;\n",
    "- NO : Concentration en monoxyde d'azote ;\n",
    "- STATION : Lieu de l'observation (Aix-en-Provence, Rambouillet, Munchhausen, Cadarache et Plan de Cuques) ;\n",
    "- VentMOD : Force du vent ;\n",
    "- VentANG : Orientation du vent.\n",
    "\n",
    "Ce sont des données bien codées et de petite taille. Elles présentent avant tout un caractère pédagogique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c29e4",
   "metadata": {},
   "source": [
    "## 2. Prise en main des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d6ba8",
   "metadata": {},
   "source": [
    "Afin de charger et d'étudier les données, nous allons utiliser la librairie pandas pour bénéficier de la classe DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e2940",
   "metadata": {},
   "source": [
    "### 2.1. Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd3af0",
   "metadata": {},
   "source": [
    "#### Importation des librairies pour le traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61495f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e119b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des données\n",
    "Ozone_DF = pd.read_csv('depSeuil.csv', sep = ',', header = 0)\n",
    "\n",
    "# typage des données\n",
    "Ozone_DF[\"STATION\"] = pd.Categorical(Ozone_DF[\"STATION\"], ordered = False)\n",
    "Ozone_DF[\"JOUR\"] = pd.Categorical(Ozone_DF[\"JOUR\"], ordered = False)\n",
    "Ozone_DF[\"O3obs\"] = pd.DataFrame(Ozone_DF[\"O3obs\"], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c474da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation du typage des données\n",
    "Ozone_DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation du jeu de données\n",
    "Ozone_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be86ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation des details du jeu de données\n",
    "Ozone_DF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67311ae4",
   "metadata": {},
   "source": [
    "ici nous avons 1041 entrées dans notre jeu de données, deux variables categorisée (JOUR ET STATION) et huit variables type float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae86f74",
   "metadata": {},
   "source": [
    "### 2.2. Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deca1b5",
   "metadata": {},
   "source": [
    "### Exploration uni-dimensionelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b04794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d185ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramme des données\n",
    "fig, axs = plt.subplots(nrows = 3, ncols = 3)\n",
    "\n",
    "i_name = 0\n",
    "            \n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "            i_name = i_name+1\n",
    "            name_col = Ozone_DF.columns[i_name]\n",
    "            axs[i, j].hist(Ozone_DF[name_col])\n",
    "            axs[i, j].set_title(name_col)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181aca0",
   "metadata": {},
   "source": [
    "### Transformation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258188e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5019a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ozone_DF[\"SRMH2O\"] = Ozone_DF[\"RMH2O\"].map(lambda x: sqrt(x))\n",
    "Ozone_DF[\"LNO2\"] = Ozone_DF[\"NO2\"].map(lambda x: log(x))\n",
    "Ozone_DF[\"LNO\"] = Ozone_DF[\"NO\"].map(lambda x: log(x))\n",
    "del Ozone_DF[\"RMH2O\"]\n",
    "del Ozone_DF[\"NO2\"]\n",
    "del Ozone_DF[\"NO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba7b8d",
   "metadata": {},
   "source": [
    "### Réponses aux questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bbdfb",
   "metadata": {},
   "source": [
    "Question 1 : ici nous avons effectué les tranformations suivnant:\n",
    "        remplacer respectivement les colones RMH2O, NO2, NO, par les colones SRMH2O,LNO2,LNO \n",
    "        remplacer chaque valeur d'observation de RMH2O par sa racine carrée et celles de NO,, NO2 par le log\n",
    "        Objectif:\n",
    "        Cette transformation nous d'avoir une distribution uniforme des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d40c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ozone_Dum = pd.get_dummies(Ozone_DF[[\"JOUR\", \"STATION\"]])\n",
    "del Ozone_Dum[\"JOUR_0\"]\n",
    "\n",
    "Ozone_Quant = Ozone_DF[[\"MOCAGE\", \"TEMPE\", \"VentMOD\", \"VentANG\", \"SRMH2O\", \"LNO2\", \"LNO\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb41b10",
   "metadata": {},
   "source": [
    "Question 2 : ici nous avons convertis les variables catégorielle(\"JOUR\", \"STATION\") en des variables fictives/indicateurs.\n",
    "    et nous avons gardé que les variables quantificateurs dans notre DataFrame\n",
    "    objectif: Cette transformation nous permettra d'avoir que des valeurs quantitatives continues que l'on pourra utiliser uterieurement pour effectuer des calcules ou des mesures "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549ec02",
   "metadata": {},
   "source": [
    "### Exploration multi-dimensionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49677f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(Ozone_DF[[\"O3obs\", \"MOCAGE\", \"TEMPE\", \"VentMOD\", \"VentANG\", \"SRMH2O\", \"LNO2\", \"LNO\"]], alpha=0.2, figsize=(15, 15), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04a3a1",
   "metadata": {},
   "source": [
    "### 2.3. Création de l'ensemble d'apprentissage / validation et de l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([Ozone_Dum, Ozone_Quant], axis = 1)\n",
    "Y = Ozone_DF[\"O3obs\"]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34869ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_2, Y_1, Y_2 = train_test_split(X, Y, train_size = 400, test_size = 200, random_state = 42)\n",
    "\n",
    "X_av = X_1.to_numpy()\n",
    "X_t = X_2.to_numpy()\n",
    "Y_av = np.transpose([Y_1.to_numpy()])\n",
    "Y_t = np.transpose([Y_2.to_numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb08c5e",
   "metadata": {},
   "source": [
    "**Remarque.** Scikit-learn fonctionne avec des numpy array. Nous allons donc utiliser les indices des colonnes:\n",
    "\n",
    "0. JOUR\n",
    "1. STATION_Aix \n",
    "2. STATION_Als \n",
    "3. STATION_Cad \n",
    "4. STATION_Pla\n",
    "5. STATION_Ram\n",
    "6. MOCAGE\n",
    "7. TEMPE\n",
    "8. VentMOD\n",
    "9. VentANG\n",
    "10. SRMH2O\n",
    "11. LNO2\n",
    "12. LNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a24a3",
   "metadata": {},
   "source": [
    "## 3. Régression linéaire univariée\n",
    "\n",
    "### 3.1. Relation unidimensionelle \n",
    "\n",
    "On étudie la qualité de la relation $\\hat{Y} = X$, où $\\hat{Y}$ est le vecteur de prédiction de l'O3 observée et $X$ le vecteur des prévisions de l'O3 observée calculée par Météo France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97772a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ad509",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows = 1, ncols = 2)\n",
    "\n",
    "axs[0].plot(X_av[:,[6]], Y_av, 'o')\n",
    "axs[0].plot([0, 300], [0, 300], 'r')\n",
    "axs[0].set_xlabel('Mocage: $X^6 = \\hat{Y}_{av}$')\n",
    "axs[0].set_ylabel('O3 observée: $Y_{av}$')\n",
    "\n",
    "axs[1].plot(X_av[:,[6]], Y_av - X_av[:,[6]], 'o')\n",
    "axs[1].plot([0, 300], [0, 0], 'r')\n",
    "axs[1].set_xlabel('Mocage: $X^6= \\hat{Y}_{av}$')\n",
    "axs[1].set_ylabel('Résidus')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Coefficient de détermination :\", r2_score(Y_av, X_av[:,[6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832374dc",
   "metadata": {},
   "source": [
    "**Question.**: Commentaire des résultats:\n",
    "\n",
    "Dans notre cas d'etude ici, nous utilisons une relation unidimensionnel en entrée (où les observations dépendent seulement de la variable x = MOCAGE).\n",
    "\n",
    "Clairement, d'après la visualisation, on peut se dire que la concentration d'ozone effectivement observée dépend de manière linéaire de la prévision de cette pollution (MOCAGE).On peut donc émettre une hypothèse de modélisation qui est que le phénomène possède la forme d'une droite. \n",
    "\n",
    "Aussi, on peut voir que lorsque la previson de pollution (Mocage) devient un peu trop grande, les données semblent devenir plus concentrées c'est à dire moins modélisables facilement, il y a plus de variabilité. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf2213",
   "metadata": {},
   "source": [
    "## 3.2. Régression linéaire ordinaire \n",
    "\n",
    "On étudie la qualité de la relation $\\hat{Y} = X\\beta + \\epsilon$, où $\\hat{Y}$ est le vecteur de prédiction de l'O3 observée et $X$ le vecteur des prévisions de l'O3 observée calculée par Météo France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20936da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(X_av[:,[6]], Y_av)\n",
    "Y_hat_av = ols.predict(X_av[:,[6]])\n",
    "\n",
    "print(\"Coefficient de régression : \\n\", ols.coef_)\n",
    "print()\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 2, sharex = True)\n",
    "\n",
    "axs[0].plot(X_av[:,[6]], Y_av, 'o')\n",
    "axs[0].plot(X_av[:,[6]], Y_hat_av, 'r-')\n",
    "#axs[0].set_ylim(0, 300)\n",
    "axs[0].set_xlabel('Régression Mocage: $\\hat{Y}_{av}$')\n",
    "axs[0].set_ylabel('O3 observée: $Y_{av}$')\n",
    "\n",
    "axs[1].plot(Y_hat_av, Y_av - Y_hat_av, 'o')\n",
    "axs[1].plot([0, 300], [0, 0], 'r')\n",
    "axs[1].set_xlabel('Prédiction Mocage: $\\hat{Y}_{av}$')\n",
    "axs[1].set_ylabel('Résidus')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Erreur quadratique (learning set) : %.2f\" % mean_squared_error(Y_av, Y_hat_av))\n",
    "print(\"Coefficient de détermination (learning set) : %.2f\" % r2_score(Y_av, Y_hat_av))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94453f64",
   "metadata": {},
   "source": [
    "**Questions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7077c",
   "metadata": {},
   "source": [
    "Q1. Pourquoi n'y a-t-il qu'un seul coefficient ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537fee0",
   "metadata": {},
   "source": [
    "R1 :Nous avons un seul coefficient de regression car nous avons consideré qu'une seule variable (MOCAGE) sur notre jeu de donné"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5bbae",
   "metadata": {},
   "source": [
    "Q2. Commentez les résultats.\n",
    "ici nous voyons que le coefficient de determination est plus important sur le modele où nous avons appliquer une apprentissage sur notre jeu de données (0.35) alors que dans notre premier nous avons mesurer le coefficient de determination juste en fonction de la linaerité de notre variable considée en fonction du phenomene observé (0.17). Ainsi la valeur (0.35) optenue à la suite de l'apprentissage semble etre plus proches de realité du phenomene observé que celle mesurée (0.17)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23669bc5",
   "metadata": {},
   "source": [
    "# 4. Régression linéaire multivariée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5725f",
   "metadata": {},
   "source": [
    "### 4.1. Régression linéaire ordinaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f81fcc",
   "metadata": {},
   "source": [
    "**Resolution de l'Exercice.** \n",
    "Question 1: Appliquez une régression linéaire sur l'ensemble d'apprentissage $(X_{av}, Y_{av})$ et évaluez la qualité des résultats en comparantc eux obtenus sur $(X_{av}, Y_{av})$ et sur $(X_{t}, Y_{t})$. Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174aff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "model_lin = ols.fit(X_av, Y_av)\n",
    "Y_hat_t = ols.predict(X_t)\n",
    "\n",
    "print(\"Coefficient de régression : \\n\", ols.coef_)\n",
    "print()\n",
    "\n",
    "print(\"Erreur quadratique (TestSet) : %.2f\" % mean_squared_error(Y_t, Y_hat_t))\n",
    "print(\"Coefficient de détermination (TestingSet) : %.2f\" % r2_score(Y_t, Y_hat_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318ef6a",
   "metadata": {},
   "source": [
    "***commentaire***:\n",
    "Ici nous appris sur l'ensemble de notre jeu de donnnées(X_av) mais nous avons testé avec notre jeu de données testingSet(X_t) . Nous voyons clairement que l'erreur quadratique obtenue sur l'ensemble de notre jeu de données (959.51) est moins importante que celle obtenue si on considere une seule variable (1125.92)le coefficient de determination est inferieur (0.42) que celui obtenu avec une seule variable (0.35).Donc notre modele a une capacité de generalisation meilleure si l'on considere lensemble des variables de notre jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c208a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model_lin.coef_[0], index =  X_1.columns)\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients de regression Lineaire\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e145e8",
   "metadata": {},
   "source": [
    "***Question 2***: Observez les coefficients de régression et commentez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1fcd41",
   "metadata": {},
   "source": [
    "ici nous avons 13 coeficients de regressions qui varient selon les variables observés et on remarque que la SRMH2O impact le plus sur le modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eac029",
   "metadata": {},
   "source": [
    "## 4.2. Régression linéaire pénalisée : Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cceda55",
   "metadata": {},
   "source": [
    "## Réponses aux questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f144cb4",
   "metadata": {},
   "source": [
    "Q1: Le but principal de la régression Ridge est de trouver les coefficients qui minimisent la somme des carrés d'erreur en appliquant une pénalité à ces coefficients.\n",
    "\n",
    "Ce paramètre de réglage est déterminé comme alpha dans le modèle. Tout d'abord, nous configurons le modèle avant de trouver le paramètre de réglage optimal.\n",
    "\n",
    "Les coefficients du modèle de régression établi peuvent être vus comme suit.\n",
    "\n",
    "La constante du modèle peut être vue comme suit.\n",
    "\n",
    "Créons un ensemble aléatoire de valeurs alpha pour trouver le paramètre alpha optimal.\n",
    "\n",
    "Sauvegardons l'ensemble sous lambda_values.\n",
    "\n",
    "Ensuite, nous construisons un modèle Ridge. De plus, nous créons un ensemble vide de coefficients. Nous créons le modèle en ajustant chaque valeur alpha dans l'ensemble de valeurs alpha que nous avons créé, puis en ajoutant les coefficients calculés à l'ensemble de coefficients que nous avons créé précédemment.\n",
    "\n",
    "Nous pouvons voir comment les coefficients changent en fonction des données alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad312876",
   "metadata": {},
   "source": [
    "Nous allons observer sur l'ensemble d'apprentissage, pour 3 valeurs de alpha ( 𝜆  dans le cours), le comportement de la regression ridge sur les coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22030013",
   "metadata": {},
   "source": [
    "#### Modèle 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_a01 = linear_model.Ridge(alpha = 0.1)\n",
    "model_r_a01 = r_a01.fit(X_av, Y_av)\n",
    "Y_hat_av_r01 = r_a01.predict(X_av)\n",
    "Y_hat_t_r01 = r_a01.predict(X_t)\n",
    "\n",
    "print(\"Erreur quadratique (learning set) : %.2f\" % mean_squared_error(Y_av, Y_hat_av_r01))\n",
    "print(\"Coefficient de détermination (learning set) : %.2f\" % r2_score(Y_av, Y_hat_av_r01))\n",
    "\n",
    "coef = pd.Series(model_r_a01.coef_[0], index =  X.columns)\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients ridge pour alpha = 0.1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeafdce",
   "metadata": {},
   "source": [
    "#### Modèle 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_a1 = linear_model.Ridge(alpha = 1)\n",
    "model_r_a1 = r_a1.fit(X_av, Y_av)\n",
    "Y_hat_av_r1 = r_a1.predict(X_av)\n",
    "Y_hat_t_r1 = r_a1.predict(X_t)\n",
    "\n",
    "print(\"Erreur quadratique (learning set) : %.2f\" % mean_squared_error(Y_av, Y_hat_av_r1))\n",
    "print(\"Coefficient de détermination (learning set) : %.2f\" % r2_score(Y_av, Y_hat_av_r1))\n",
    "\n",
    "coef = pd.Series(model_r_a1.coef_[0], index =  X.columns)\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients ridge pour alpha = 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d76f1",
   "metadata": {},
   "source": [
    "#### Modèle 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f731f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_a10 = linear_model.Ridge(alpha = 10)\n",
    "model_r_a10 = r_a10.fit(X_av, Y_av)\n",
    "Y_hat_av_r10 = r_a10.predict(X_av)\n",
    "Y_hat_t_r10 = r_a10.predict(X_t)\n",
    "\n",
    "print(\"Erreur quadratique (learning set) : %.2f\" % mean_squared_error(Y_av, Y_hat_av_r10))\n",
    "print(\"Coefficient de détermination (learning set) : %.2f\" % r2_score(Y_av, Y_hat_av_r10))\n",
    "\n",
    "coef = pd.Series(model_r_a10.coef_[0], index =  X.columns)\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients ridge pour alpha = 10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58df99",
   "metadata": {},
   "source": [
    "# Q1. Commentaitre : \n",
    "Apres visualisation, nous constatons que l'évolution du comportement sur les coefficients evoluent selon que la valeur de alpha augmente. Cela s'explique du fait que plus alpha est grand plus on penalise les coefficients et plus alpha est proche de 0 moins on penalise et plus le fait de minimiser l'erreur de prediction contraint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c8e82",
   "metadata": {},
   "source": [
    "#### Solution de l'exercice :  Visualisons globalement l'évolution des coefficients en fonction de alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfeba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alphas = [0.1, 1, 10]\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=a, fit_intercept=False)\n",
    "    ridge.fit(X_av, Y_av)\n",
    "    coefs.append(ridge.coef_[0])\n",
    "    \n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")\n",
    "#ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Coefs\")\n",
    "plt.title(\"Ridge coefficients as a function of the regularization\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e3fae",
   "metadata": {},
   "source": [
    "## Mettez en place une procédure d'apprentissage rigoureuse pour trouver le paramètre alpha optimal de la régression ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251158b",
   "metadata": {},
   "source": [
    "### Etape 1 : Application d'une regression lineaire simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8e561",
   "metadata": {},
   "source": [
    "## Application de la régression ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e11485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddf2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407450f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciation du model\n",
    "ridge_reg = linear_model.Ridge()\n",
    "\n",
    "#definition des valeur de alpha\n",
    "params_Ridge = {'alpha': [0.1, 1, 10] , \"fit_intercept\": [True, False]}\n",
    "\n",
    "\n",
    "#Recherche de meilleur parametre\n",
    "Ridge_GS = GridSearchCV(ridge_reg,\n",
    "                        param_grid=params_Ridge,\n",
    "                       )\n",
    "#Apprentissage du model\n",
    "ridge = Ridge_GS.fit(X_av, Y_av)\n",
    "\n",
    "scores = Ridge_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = Ridge_GS.cv_results_[\"std_test_score\"]\n",
    "\n",
    "print(\"Résultats de la validation Croisé sur l'ensemble des paramètres:\")   \n",
    "print(\"Meilleurs paramètres alpha du Ridge:\")\n",
    "print(Ridge_GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cca48e",
   "metadata": {},
   "source": [
    "### Commentaire :\n",
    "ici la valeur optimale de alpha de la regression ridge est : alpha = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102179e",
   "metadata": {},
   "source": [
    "# 4.3. Régression linéaire pénalisée : Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a1c0b",
   "metadata": {},
   "source": [
    "### Reponses aux questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedebf61",
   "metadata": {},
   "source": [
    "la régression lasso est un type de régression linéaire qui permet de réduire les limites du modèle. Les valeurs des données se réduisent au centre ou à la moyenne pour éviter de surcharger les données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa62cc6",
   "metadata": {},
   "source": [
    "## Application de la régression Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c871a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso()\n",
    "\n",
    "#definition des valeur de alpha\n",
    "params_Lasso = {'alpha': [0.1, 1, 10] , \"fit_intercept\": [True, False]}\n",
    "\n",
    "\n",
    "#Recherche de meilleur parametre\n",
    "Lasso_GS = GridSearchCV(lasso,\n",
    "                        param_grid=params_Lasso,\n",
    "                       )\n",
    "#Apprentissage du model\n",
    "lasso = Lasso_GS.fit(X_av, Y_av)\n",
    "\n",
    "scores = Lasso_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = Lasso_GS.cv_results_[\"std_test_score\"]\n",
    "\n",
    "print(\"Résultats de la validation Croisé (Lasso) sur l'ensemble des paramètres:\")   \n",
    "print(\"Meilleurs paramètres alpha du Lasso :\")\n",
    "print(Lasso_GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838f45",
   "metadata": {},
   "source": [
    "### Commentaire :\n",
    "ici la valeur optimale de alpha de la regression Lasso est : alpha = 0.1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
