{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2eeed49",
   "metadata": {},
   "source": [
    "# TP DE REGRESSION LINEAIRE\n",
    "\n",
    "**Cr√©dits.** Ce TP est largement inspir√© du sc√©nario disponible sur Wikistat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0173527c",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d217433c",
   "metadata": {},
   "source": [
    "### Objectif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a455b1",
   "metadata": {},
   "source": [
    "L'objectif de cette est d'am√©liorer la pr√©vision d√©terministe (MOCAGE), calcul√©e par les services de M√©t√©o France, de la concentration d'ozone dans certaines stations de pr√©l√®vement. Il s'agit d'un probl√®me dit d'adaptation statistique ou post-traitement d'une pr√©vision locale de mod√®les √† trop grande √©chelle en s'aidant d'autre variables √©galement g√©r√©es par M√©t√©oFrance, mais √† plus petite √©chelle (temp√©rature, force du vent, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19f337",
   "metadata": {},
   "source": [
    "### Description des donn√©es "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119d2e5",
   "metadata": {},
   "source": [
    "Les donn√©es ont √©t√© extraites et mises en forme par le service concern√© de M√©t√©o France. Elles sont d√©crites par les variables suivantes:\n",
    "- JOUR : Type de jour (f√©ri√© (1) ou pas (0) ;\n",
    "- O3obs : Concentration d'ozone effectivement observ√©e le lendemain √† 17h locales correspondant souvent au maximum de pollution observ√©e ;\n",
    "- MOCAGE : Pr√©vision de cette pollution obtenue par un mod√®le d√©terministe de m√©canique des fluides (√©quation de Navier et Stockes);\n",
    "- TEMPE : Temp√©rature pr√©vue par M√©t√©oFrance pour le lendemain 17h ;\n",
    "- RMH2O : Rapport d'humidit√© ;\n",
    "- NO2 : Concentration en dioxyde d'azote ;\n",
    "- NO : Concentration en monoxyde d'azote ;\n",
    "- STATION : Lieu de l'observation (Aix-en-Provence, Rambouillet, Munchhausen, Cadarache et Plan de Cuques) ;\n",
    "- VentMOD : Force du vent ;\n",
    "- VentANG : Orientation du vent.\n",
    "\n",
    "Ce sont des donn√©es bien cod√©es et de petite taille. Elles pr√©sentent avant tout un caract√®re p√©dagogique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c29e4",
   "metadata": {},
   "source": [
    "## 2. Prise en main des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d6ba8",
   "metadata": {},
   "source": [
    "Afin de charger et d'√©tudier les donn√©es, nous allons utiliser la librairie pandas pour b√©n√©ficier de la classe DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75e2940",
   "metadata": {},
   "source": [
    "### 2.1. Chargement des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd3af0",
   "metadata": {},
   "source": [
    "#### Importation des librairies pour le traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61495f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e119b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des donn√©es\n",
    "Ozone_DF = pd.read_csv('depSeuil.csv', sep = ',', header = 0)\n",
    "\n",
    "# typage des donn√©es\n",
    "Ozone_DF[\"STATION\"] = pd.Categorical(Ozone_DF[\"STATION\"], ordered = False)\n",
    "Ozone_DF[\"JOUR\"] = pd.Categorical(Ozone_DF[\"JOUR\"], ordered = False)\n",
    "Ozone_DF[\"O3obs\"] = pd.DataFrame(Ozone_DF[\"O3obs\"], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c474da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation du typage des donn√©es\n",
    "Ozone_DF.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation du jeu de donn√©es\n",
    "Ozone_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be86ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation des details du jeu de donn√©es\n",
    "Ozone_DF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67311ae4",
   "metadata": {},
   "source": [
    "ici nous avons 1041 entr√©es dans notre jeu de donn√©es, deux variables categoris√©e (JOUR ET STATION) et huit variables type float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae86f74",
   "metadata": {},
   "source": [
    "### 2.2. Exploration des donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deca1b5",
   "metadata": {},
   "source": [
    "### Exploration uni-dimensionelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b04794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d185ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramme des donn√©es\n",
    "fig, axs = plt.subplots(nrows = 3, ncols = 3)\n",
    "\n",
    "i_name = 0\n",
    "            \n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "            i_name = i_name+1\n",
    "            name_col = Ozone_DF.columns[i_name]\n",
    "            axs[i, j].hist(Ozone_DF[name_col])\n",
    "            axs[i, j].set_title(name_col)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f181aca0",
   "metadata": {},
   "source": [
    "### Transformation du jeu de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258188e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5019a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ozone_DF[\"SRMH2O\"] = Ozone_DF[\"RMH2O\"].map(lambda x: sqrt(x))\n",
    "Ozone_DF[\"LNO2\"] = Ozone_DF[\"NO2\"].map(lambda x: log(x))\n",
    "Ozone_DF[\"LNO\"] = Ozone_DF[\"NO\"].map(lambda x: log(x))\n",
    "del Ozone_DF[\"RMH2O\"]\n",
    "del Ozone_DF[\"NO2\"]\n",
    "del Ozone_DF[\"NO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ba7b8d",
   "metadata": {},
   "source": [
    "### R√©ponses aux questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bbdfb",
   "metadata": {},
   "source": [
    "Question 1 : ici nous avons effectu√© les tranformations suivnant:\n",
    "        remplacer respectivement les colones RMH2O, NO2, NO, par les colones SRMH2O,LNO2,LNO \n",
    "        remplacer chaque valeur d'observation de RMH2O par sa racine carr√©e et celles de NO,, NO2 par le log\n",
    "        Objectif:\n",
    "        Cette transformation nous d'avoir une distribution uniforme des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d40c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ozone_Dum = pd.get_dummies(Ozone_DF[[\"JOUR\", \"STATION\"]])\n",
    "del Ozone_Dum[\"JOUR_0\"]\n",
    "\n",
    "Ozone_Quant = Ozone_DF[[\"MOCAGE\", \"TEMPE\", \"VentMOD\", \"VentANG\", \"SRMH2O\", \"LNO2\", \"LNO\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb41b10",
   "metadata": {},
   "source": [
    "Question 2 : ici nous avons convertis les variables cat√©gorielle(\"JOUR\", \"STATION\") en des variables fictives/indicateurs.\n",
    "    et nous avons gard√© que les variables quantificateurs dans notre DataFrame\n",
    "    objectif: Cette transformation nous permettra d'avoir que des valeurs quantitatives continues que l'on pourra utiliser uterieurement pour effectuer des calcules ou des mesures "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549ec02",
   "metadata": {},
   "source": [
    "### Exploration multi-dimensionnelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49677f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(Ozone_DF[[\"O3obs\", \"MOCAGE\", \"TEMPE\", \"VentMOD\", \"VentANG\", \"SRMH2O\", \"LNO2\", \"LNO\"]], alpha=0.2, figsize=(15, 15), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04a3a1",
   "metadata": {},
   "source": [
    "### 2.3. Cr√©ation de l'ensemble d'apprentissage / validation et de l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([Ozone_Dum, Ozone_Quant], axis = 1)\n",
    "Y = Ozone_DF[\"O3obs\"]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00f7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import StandardScaler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34869ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_2, Y_1, Y_2 = train_test_split(X, Y, train_size = 400, test_size = 200, random_state = 42)\n",
    "\n",
    "X_av = X_1.to_numpy()\n",
    "X_t = X_2.to_numpy()\n",
    "Y_av = np.transpose([Y_1.to_numpy()])\n",
    "Y_t = np.transpose([Y_2.to_numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb08c5e",
   "metadata": {},
   "source": [
    "**Remarque.** Scikit-learn fonctionne avec des numpy array. Nous allons donc utiliser les indices des colonnes:\n",
    "\n",
    "0. JOUR\n",
    "1. STATION_Aix \n",
    "2. STATION_Als \n",
    "3. STATION_Cad \n",
    "4. STATION_Pla\n",
    "5. STATION_Ram\n",
    "6. MOCAGE\n",
    "7. TEMPE\n",
    "8. VentMOD\n",
    "9. VentANG\n",
    "10. SRMH2O\n",
    "11. LNO2\n",
    "12. LNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a24a3",
   "metadata": {},
   "source": [
    "## 3. R√©gression lin√©aire univari√©e\n",
    "\n",
    "### 3.1. Relation unidimensionelle \n",
    "\n",
    "On √©tudie la qualit√© de la relation $\\hat{Y} = X$, o√π $\\hat{Y}$ est le vecteur de pr√©diction de l'O3 observ√©e et $X$ le vecteur des pr√©visions de l'O3 observ√©e calcul√©e par M√©t√©o France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97772a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ad509",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows = 1, ncols = 2)\n",
    "\n",
    "axs[0].plot(X_av[:,[6]], Y_av, 'o')\n",
    "axs[0].plot([0, 300], [0, 300], 'r')\n",
    "axs[0].set_xlabel('Mocage: $X^6 = \\hat{Y}_{av}$')\n",
    "axs[0].set_ylabel('O3 observ√©e: $Y_{av}$')\n",
    "\n",
    "axs[1].plot(X_av[:,[6]], Y_av - X_av[:,[6]], 'o')\n",
    "axs[1].plot([0, 300], [0, 0], 'r')\n",
    "axs[1].set_xlabel('Mocage: $X^6= \\hat{Y}_{av}$')\n",
    "axs[1].set_ylabel('R√©sidus')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Coefficient de d√©termination :\", r2_score(Y_av, X_av[:,[6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832374dc",
   "metadata": {},
   "source": [
    "**Question.**: Commentaire des r√©sultats:\n",
    "\n",
    "Dans notre cas d'etude ici, nous utilisons une relation unidimensionnel en entr√©e (o√π les observations d√©pendent seulement de la variable x = MOCAGE).\n",
    "\n",
    "Clairement, d'apr√®s la visualisation, on peut se dire que la concentration d'ozone effectivement observ√©e d√©pend de mani√®re lin√©aire de la pr√©vision de cette pollution (MOCAGE).On peut donc √©mettre une hypoth√®se de mod√©lisation qui est que le ph√©nom√®ne poss√®de la forme d'une droite. \n",
    "\n",
    "Aussi, on peut voir que lorsque la previson de pollution (Mocage) devient un peu trop grande, les donn√©es semblent devenir plus concentr√©es c'est √† dire moins mod√©lisables facilement, il y a plus de variabilit√©. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf2213",
   "metadata": {},
   "source": [
    "## 3.2. R√©gression lin√©aire ordinaire \n",
    "\n",
    "On √©tudie la qualit√© de la relation $\\hat{Y} = X\\beta + \\epsilon$, o√π $\\hat{Y}$ est le vecteur de pr√©diction de l'O3 observ√©e et $X$ le vecteur des pr√©visions de l'O3 observ√©e calcul√©e par M√©t√©o France."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20936da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "ols.fit(X_av[:,[6]], Y_av)\n",
    "Y_hat_av = ols.predict(X_av[:,[6]])\n",
    "\n",
    "print(\"Coefficient de r√©gression : \\n\", ols.coef_)\n",
    "print()\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 2, sharex = True)\n",
    "\n",
    "axs[0].plot(X_av[:,[6]], Y_av, 'o')\n",
    "axs[0].plot(X_av[:,[6]], Y_hat_av, 'r-')\n",
    "#axs[0].set_ylim(0, 300)\n",
    "axs[0].set_xlabel('R√©gression Mocage: $\\hat{Y}_{av}$')\n",
    "axs[0].set_ylabel('O3 observ√©e: $Y_{av}$')\n",
    "\n",
    "axs[1].plot(Y_hat_av, Y_av - Y_hat_av, 'o')\n",
    "axs[1].plot([0, 300], [0, 0], 'r')\n",
    "axs[1].set_xlabel('Pr√©diction Mocage: $\\hat{Y}_{av}$')\n",
    "axs[1].set_ylabel('R√©sidus')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Erreur quadratique (learning set) : %.2f\" % mean_squared_error(Y_av, Y_hat_av))\n",
    "print(\"Coefficient de d√©termination (learning set) : %.2f\" % r2_score(Y_av, Y_hat_av))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94453f64",
   "metadata": {},
   "source": [
    "**Questions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b7077c",
   "metadata": {},
   "source": [
    "Q1. Pourquoi n'y a-t-il qu'un seul coefficient ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1537fee0",
   "metadata": {},
   "source": [
    "R1 :Nous avons un seul coefficient de regression car nous avons consider√© qu'une seule variable (MOCAGE) sur notre jeu de donn√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b5bbae",
   "metadata": {},
   "source": [
    "Q2. Commentez les r√©sultats.\n",
    "ici nous voyons que le coefficient de determination est plus important sur le modele o√π nous avons appliquer une apprentissage sur notre jeu de donn√©es (0.35) alors que dans notre premier nous avons mesurer le coefficient de determination juste en fonction de la linaerit√© de notre variable consid√©e en fonction du phenomene observ√© (0.17). Ainsi la valeur (0.35) optenue √† la suite de l'apprentissage semble etre plus proches de realit√© du phenomene observ√© que celle mesur√©e (0.17)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23669bc5",
   "metadata": {},
   "source": [
    "# 4. R√©gression lin√©aire multivari√©e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5725f",
   "metadata": {},
   "source": [
    "### 4.1. R√©gression lin√©aire ordinaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f81fcc",
   "metadata": {},
   "source": [
    "**Resolution de l'Exercice.** \n",
    "Question 1: Appliquez une r√©gression lin√©aire sur l'ensemble d'apprentissage $(X_{av}, Y_{av})$ et √©valuez la qualit√© des r√©sultats en comparantc eux obtenus sur $(X_{av}, Y_{av})$ et sur $(X_{t}, Y_{t})$. Commentez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174aff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols = linear_model.LinearRegression()\n",
    "model_lin = ols.fit(X_av, Y_av)\n",
    "Y_hat_t = ols.predict(X_t)\n",
    "\n",
    "print(\"Coefficient de r√©gression : \\n\", ols.coef_)\n",
    "print()\n",
    "\n",
    "print(\"Erreur quadratique (TestSet) : %.2f\" % mean_squared_error(Y_t, Y_hat_t))\n",
    "print(\"Coefficient de d√©termination (TestingSet) : %.2f\" % r2_score(Y_t, Y_hat_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318ef6a",
   "metadata": {},
   "source": [
    "***commentaire***:\n",
    "Ici nous appris sur l'ensemble de notre jeu de donnn√©es(X_av) mais nous avons test√© avec notre jeu de donn√©es testingSet(X_t) . Nous voyons clairement que l'erreur quadratique obtenue sur l'ensemble de notre jeu de donn√©es (959.51) est moins importante que celle obtenue si on considere une seule variable (1125.92)le coefficient de determination est inferieur (0.42) que celui obtenu avec une seule variable (0.35).Donc notre modele a une capacit√© de generalisation meilleure si l'on considere lensemble des variables de notre jeu de donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c208a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model_lin.coef_[0], index =  X_1.columns)\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients de regression Lineaire\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e145e8",
   "metadata": {},
   "source": [
    "***Question 2***: Observez les coefficients de r√©gression et commentez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1fcd41",
   "metadata": {},
   "source": [
    "ici nous avons 13 coeficients de regressions qui varient selon les variables observ√©s et on remarque que la SRMH2O impact le plus sur le modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eac029",
   "metadata": {},
   "source": [
    "## 4.2. R√©gression lin√©aire p√©nalis√©e : Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cceda55",
   "metadata": {},
   "source": [
    "## R√©ponses aux questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f144cb4",
   "metadata": {},
   "source": [
    "Q1: Le but principal de la r√©gression Ridge est de trouver les coefficients qui minimisent la somme des carr√©s d'erreur en appliquant une p√©nalit√© √† ces coefficients.\n",
    "\n",
    "Ce param√®tre de r√©glage est d√©termin√© comme alpha dans le mod√®le. Tout d'abord, nous configurons le mod√®le avant de trouver le param√®tre de r√©glage optimal.\n",
    "\n",
    "Les coefficients du mod√®le de r√©gression √©tabli peuvent √™tre vus comme suit.\n",
    "\n",
    "La constante du mod√®le peut √™tre vue comme suit.\n",
    "\n",
    "Cr√©ons un ensemble al√©atoire de valeurs alpha pour trouver le param√®tre alpha optimal.\n",
    "\n",
    "Sauvegardons l'ensemble sous lambda_values.\n",
    "\n",
    "Ensuite, nous construisons un mod√®le Ridge. De plus, nous cr√©ons un ensemble vide de coefficients. Nous cr√©ons le mod√®le en ajustant chaque valeur alpha dans l'ensemble de valeurs alpha que nous avons cr√©√©, puis en ajoutant les coefficients calcul√©s √† l'ensemble de coefficients que nous avons cr√©√© pr√©c√©demment.\n",
    "\n",
    "Nous pouvons voir comment les coefficients changent en fonction des donn√©es alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad312876",
   "metadata": {},
   "source": [
    "Nous allons observer sur l'ensemble d'apprentissage, pour 3 valeurs de alpha ( ùúÜ  dans le cours), le comportement de la regression ridge sur les coefficients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22030013",
   "metadata": {},
   "source": [
    "#### Mod√®le 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_a01 = linear_model.Ridge(alpha = 0.1)\n",
    "model_r_a01 = r_a01.fit(X_av, Y_av)\n",
    "Y_hat_av_r01 = r_a01.predict(X_av)\n",
    "Y_hat_t_r01 = r_a01.predict(X_t)\n",
    "\n",
    "print(\"Erreur quadratique (learning set) : %.2f\" % mean_squared_error(Y_av, Y_hat_av_r01))\n",
    "print(\"Coefficient de d√©termination (learning set) : %.2f\" % r2_score(Y_av, Y_hat_av_r01))\n",
    "\n",
    "coef = pd.Series(model_r_a01.coef_[0], index =  X.columns)\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients ridge pour alpha = 0.1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeafdce",
   "metadata": {},
   "source": [
    "#### Mod√®le 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04afeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_a1 = linear_model.Ridge(alpha = 1)\n",
    "model_r_a1 = r_a1.fit(X_av, Y_av)\n",
    "Y_hat_av_r1 = r_a1.predict(X_av)\n",
    "Y_hat_t_r1 = r_a1.predict(X_t)\n",
    "\n",
    "print(\"Erreur quadratique (learning set) : %.2f\" % mean_squared_error(Y_av, Y_hat_av_r1))\n",
    "print(\"Coefficient de d√©termination (learning set) : %.2f\" % r2_score(Y_av, Y_hat_av_r1))\n",
    "\n",
    "coef = pd.Series(model_r_a1.coef_[0], index =  X.columns)\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients ridge pour alpha = 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4d76f1",
   "metadata": {},
   "source": [
    "#### Mod√®le 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f731f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_a10 = linear_model.Ridge(alpha = 10)\n",
    "model_r_a10 = r_a10.fit(X_av, Y_av)\n",
    "Y_hat_av_r10 = r_a10.predict(X_av)\n",
    "Y_hat_t_r10 = r_a10.predict(X_t)\n",
    "\n",
    "print(\"Erreur quadratique (learning set) : %.2f\" % mean_squared_error(Y_av, Y_hat_av_r10))\n",
    "print(\"Coefficient de d√©termination (learning set) : %.2f\" % r2_score(Y_av, Y_hat_av_r10))\n",
    "\n",
    "coef = pd.Series(model_r_a10.coef_[0], index =  X.columns)\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients ridge pour alpha = 10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58df99",
   "metadata": {},
   "source": [
    "# Q1. Commentaitre : \n",
    "Apres visualisation, nous constatons que l'√©volution du comportement sur les coefficients evoluent selon que la valeur de alpha augmente. Cela s'explique du fait que plus alpha est grand plus on penalise les coefficients et plus alpha est proche de 0 moins on penalise et plus le fait de minimiser l'erreur de prediction contraint "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c8e82",
   "metadata": {},
   "source": [
    "#### Solution de l'exercice :  Visualisons globalement l'√©volution des coefficients en fonction de alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfeba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alphas = [0.1, 1, 10]\n",
    "coefs = []\n",
    "for a in alphas:\n",
    "    ridge = linear_model.Ridge(alpha=a, fit_intercept=False)\n",
    "    ridge.fit(X_av, Y_av)\n",
    "    coefs.append(ridge.coef_[0])\n",
    "    \n",
    "ax = plt.gca()\n",
    "\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale(\"log\")\n",
    "#ax.set_xlim(ax.get_xlim()[::-1])  # reverse axis\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"Coefs\")\n",
    "plt.title(\"Ridge coefficients as a function of the regularization\")\n",
    "plt.axis(\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e3fae",
   "metadata": {},
   "source": [
    "## Mettez en place une proc√©dure d'apprentissage rigoureuse pour trouver le param√®tre alpha optimal de la r√©gression ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251158b",
   "metadata": {},
   "source": [
    "### Etape 1 : Application d'une regression lineaire simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8e561",
   "metadata": {},
   "source": [
    "## Application de la r√©gression ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e11485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddf2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407450f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciation du model\n",
    "ridge_reg = linear_model.Ridge()\n",
    "\n",
    "#definition des valeur de alpha\n",
    "params_Ridge = {'alpha': [0.1, 1, 10] , \"fit_intercept\": [True, False]}\n",
    "\n",
    "\n",
    "#Recherche de meilleur parametre\n",
    "Ridge_GS = GridSearchCV(ridge_reg,\n",
    "                        param_grid=params_Ridge,\n",
    "                       )\n",
    "#Apprentissage du model\n",
    "ridge = Ridge_GS.fit(X_av, Y_av)\n",
    "\n",
    "scores = Ridge_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = Ridge_GS.cv_results_[\"std_test_score\"]\n",
    "\n",
    "print(\"R√©sultats de la validation Crois√© sur l'ensemble des param√®tres:\")   \n",
    "print(\"Meilleurs param√®tres alpha du Ridge:\")\n",
    "print(Ridge_GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cca48e",
   "metadata": {},
   "source": [
    "### Commentaire :\n",
    "ici la valeur optimale de alpha de la regression ridge est : alpha = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102179e",
   "metadata": {},
   "source": [
    "# 4.3. R√©gression lin√©aire p√©nalis√©e : Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1a1c0b",
   "metadata": {},
   "source": [
    "### Reponses aux questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedebf61",
   "metadata": {},
   "source": [
    "la r√©gression lasso est un type de r√©gression lin√©aire qui permet de r√©duire les limites du mod√®le. Les valeurs des donn√©es se r√©duisent au centre ou √† la moyenne pour √©viter de surcharger les donn√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa62cc6",
   "metadata": {},
   "source": [
    "## Application de la r√©gression Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c871a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso()\n",
    "\n",
    "#definition des valeur de alpha\n",
    "params_Lasso = {'alpha': [0.1, 1, 10] , \"fit_intercept\": [True, False]}\n",
    "\n",
    "\n",
    "#Recherche de meilleur parametre\n",
    "Lasso_GS = GridSearchCV(lasso,\n",
    "                        param_grid=params_Lasso,\n",
    "                       )\n",
    "#Apprentissage du model\n",
    "lasso = Lasso_GS.fit(X_av, Y_av)\n",
    "\n",
    "scores = Lasso_GS.cv_results_[\"mean_test_score\"]\n",
    "scores_std = Lasso_GS.cv_results_[\"std_test_score\"]\n",
    "\n",
    "print(\"R√©sultats de la validation Crois√© (Lasso) sur l'ensemble des param√®tres:\")   \n",
    "print(\"Meilleurs param√®tres alpha du Lasso :\")\n",
    "print(Lasso_GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03838f45",
   "metadata": {},
   "source": [
    "### Commentaire :\n",
    "ici la valeur optimale de alpha de la regression Lasso est : alpha = 0.1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
